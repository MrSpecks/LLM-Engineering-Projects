# Website Scraper & Summarizer\n\nThis project is a Jupyter Notebook application that allows you to scrape the contents of a website and automatically generate a concise summary using a Large Language Model (LLM). It combines web scraping techniques with natural language processing to produce easy-to-read summaries of online content.\n\n---\n\n## ‚ú® Features\n\n- Web Scraping: Uses requests and BeautifulSoup to fetch and parse website content.\n- Custom Website Object: Stores URL, title, and cleaned text.\n- AI-Powered Summarization: Uses an LLM (via the OpenAI API / local Ollama endpoint) to summarize website contents.\n- Markdown Output: Displays results in clean Markdown format directly in Jupyter.\n- Noise Filtering: Ignores navigation or repetitive elements, focusing only on meaningful content.\n\n---\n\n## üõ†Ô∏è Tech Stack\n\n- Python\n- Jupyter Notebooks\n- Libraries: \n - requests ‚Äì for HTTP requests\n - BeautifulSoup ‚Äì for HTML parsing\n - openai ‚Äì for LLM integration (configurable for local Ollama)\n - IPython.display ‚Äì for rendering Markdown summaries\n\n---\n\n## üöÄ Getting Started\n\n### 1. Clone this repository\nbash\ngit clone <your-repo-url>\ncd website-summarizer\n\n\n### 2. Set up environment\nbash\npip install -r requirements.txt\n\n\n### 3. Configure API\n- If using OpenAI, add your API key to the notebook or as an environment variable.\n- If using Ollama, ensure the service is running locally at http://localhost:11434/v1 and update the MODEL variable as needed.\n\n### 4. Run the notebook\nOpen the notebook in Jupyter and execute the cells step-by-step:\nbash\njupyter notebook \"Website Summarizer.ipynb\"\n\n\n---\n\n## üìñ Usage\n\n1. Provide the target website URL.\n2. The scraper fetches and cleans the page text.\n3. The LLM generates a concise summary.\n4. The result is displayed in Markdown inside the notebook.\n\n---\n\n## üìÇ Project Structure\n\n\nWebsite Summarizer.ipynb # Main notebook with code and instructions\nrequirements.txt # Python dependencies (to be created)\nREADME.md # Project documentation (this file)\n\n\n---\n\n## ‚ö° Example Workflow\n\n- Input: https://example.com/news\n- Scraped: Page title + body content\n- Output: "This news article announces..." (clean summary in Markdown)\n\n---\n\n## üîÆ Future Improvements\n\n- Add support for batch summarization of multiple URLs.\n- Extend to PDFs or text documents.\n- Export summaries to a database or CSV.\n- Add a web UI for easier use outside Jupyter.\n\n---\n\n## üìú License\n\nThis project is provided under the MIT License.\n
